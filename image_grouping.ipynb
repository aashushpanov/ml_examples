{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "import glob \n",
    "from skimage import io\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow.keras.layers as L\n",
    "from tensorflow.keras.models import save_model\n",
    "import tensorflow as tf\n",
    "from os import path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data_path'\n",
    "os.chdir(data_path)\n",
    "\n",
    "image_names = os.listdir(data_path)\n",
    "\n",
    "def image2array(filelist):\n",
    "    image_array = []\n",
    "    for image in filelist:\n",
    "        print('{} is loaded'.format(image, 500))\n",
    "        img = io.imread(image)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, (224,224))/225\n",
    "        image_array.append(img)\n",
    "    image_array = np.array(image_array)\n",
    "    image_array = image_array.reshape(image_array.shape[0], 224, 224, 3)\n",
    "    image_array = image_array.astype('float32')\n",
    "    image_array /= 225\n",
    "    return image_array\n",
    "\n",
    "train_data = image2array(image_names[:500])\n",
    "print(\"Length of training dataset:\", train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SHAPE = train_data.shape[1:]\n",
    "def build_deep_autoencoder(img_shape, code_size):\n",
    "    H,W,C = img_shape\n",
    "    # encoder\n",
    "    encoder = tf.keras.models.Sequential()\n",
    "    encoder.add(L.InputLayer(img_shape))\n",
    "    encoder.add(L.Conv2D(filters=32, kernel_size=(3, 3), activation='elu', padding='same'))\n",
    "    encoder.add(L.MaxPooling2D(pool_size=(2, 2)))\n",
    "    encoder.add(L.Conv2D(filters=64, kernel_size=(3, 3), activation='elu', padding='same'))\n",
    "    encoder.add(L.MaxPooling2D(pool_size=(2, 2)))\n",
    "    encoder.add(L.Conv2D(filters=128, kernel_size=(3, 3), activation='elu', padding='same'))\n",
    "    encoder.add(L.MaxPooling2D(pool_size=(2, 2)))\n",
    "    encoder.add(L.Conv2D(filters=256, kernel_size=(3, 3), activation='elu', padding='same'))\n",
    "    encoder.add(L.MaxPooling2D(pool_size=(2, 2)))\n",
    "    encoder.add(L.Flatten())\n",
    "    encoder.add(L.Dense(code_size))\n",
    "\n",
    "    # decoder\n",
    "    decoder = tf.keras.models.Sequential()\n",
    "    decoder.add(L.InputLayer((code_size,)))\n",
    "    decoder.add(L.Dense(14*14*256))\n",
    "    decoder.add(L.Reshape((14, 14, 256)))\n",
    "    decoder.add(L.Conv2DTranspose(filters=128, kernel_size=(3, 3), strides=2, activation='elu', padding='same'))\n",
    "    decoder.add(L.Conv2DTranspose(filters=64, kernel_size=(3, 3), strides=2, activation='elu', padding='same'))\n",
    "    decoder.add(L.Conv2DTranspose(filters=32, kernel_size=(3, 3), strides=2, activation='elu', padding='same'))\n",
    "    decoder.add(L.Conv2DTranspose(filters=3, kernel_size=(3, 3), strides=2, activation=None, padding='same'))\n",
    "    \n",
    "    return encoder, decoder\n",
    "\n",
    "\n",
    "encoder, decoder = build_deep_autoencoder(IMG_SHAPE, code_size=32)\n",
    "encoder.summary()\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = L.Input(IMG_SHAPE)\n",
    "code = encoder(input_layer)\n",
    "reconstruction = decoder(code)\n",
    "\n",
    "autoencoder = tf.keras.models.Model(inputs=input_layer, outputs=reconstruction)\n",
    "autoencoder.compile(optimizer=\"adamax\", loss='mse')\n",
    "autoencoder.fit(x=train_data, y=train_data, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_codes = encoder.predict(train_data)\n",
    "assert len(image_codes) == len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nei_clf = NearestNeighbors(metric=\"euclidean\")\n",
    "nei_clf.fit(image_codes)\n",
    "def get_similar(i, res, n_neighbors=6):\n",
    "    image = train_data[i]\n",
    "    name = image_names[i]\n",
    "    assert image.ndim==3\n",
    "    code = encoder.predict(image[None])\n",
    "    (distances,),(idx,) = nei_clf.kneighbors(code,n_neighbors=n_neighbors)\n",
    "    line = [name]\n",
    "    line.extend([image_names[j] for j in idx[1:]])\n",
    "    res.append(' '.join(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors = 5\n",
    "res = ['image' + ' '.join(list(map(str, [n for n in range(1, n_neighbors + 1)])))]\n",
    "for i in range(500):\n",
    "    get_similar(i, res)\n",
    "    print('{} in {}'.format(i, len(image_names, n_neighbors + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
